MetricsServerEnabled: false
datakit:
  dataway_url: https://aws-openway.guance.com?token=tkn_cef8ee496b014cd4a59b1b470a9c0679
  default_enabled_inputs: dk,cpu,disk,diskio,mem,swap,system,hostobject,net,host_processes,container,ebpf,rum,statsd,profile,ddtrace
  enabled_election: true
  global_tags: host=__datakit_hostname,host_ip=__datakit_ip，cluster_name_k8s=guance_workshop
  http_listen: 0.0.0.0:9529
  log_level: info
dkconfig:
  - path: "/usr/local/datakit/conf.d/ddtrace/ddtrace.conf"
    name: inputs.ddtrace
    value: |
      [[inputs.ddtrace]]
        ## DDTrace Agent endpoints register by version respectively.
        ## Endpoints can be skipped listen by remove them from the list.
        ## NOTE: DO NOT EDIT.
        endpoints = ["/v0.3/traces", "/v0.4/traces", "/v0.5/traces"]
        
        ## ignore_tags will work as a blacklist to prevent tags send to data center.
        ## Every value in this list is a valid string of regular expression.
        # ignore_tags = ["block1", "block2"]
        
        ## Keep rare tracing resources list switch.
        ## If some resources are rare enough(not presend in 1 hour), those resource will always send
        ## to data center and do not consider samplers and filters.
        # keep_rare_resource = false
        
        ## By default every error presents in span will be send to data center and omit any filters or
        ## sampler. If you want to get rid of some error status, you can set the error status list here.
        # omit_err_status = ["404"]
        
        ## Ignore tracing resources map like service:[resources...].
        ## The service name is the full service name in current application.
        ## The resource list is regular expressions uses to block resource names.
        ## If you want to block some resources universally under all services, you can set the
        ## service name as "*". Note: double quotes "" cannot be omitted.
        # [inputs.ddtrace.close_resource]
        # service1 = ["resource1", "resource2", ...]
        # service2 = ["resource1", "resource2", ...]
        # "*" = ["close_resource_under_all_services"]
        # ...
        
        ## Sampler config uses to set global sampling strategy.
        ## sampling_rate used to set global sampling rate.
        # [inputs.ddtrace.sampler]
        # sampling_rate = 1.0
        
        # [inputs.ddtrace.tags]
        # key1 = "value1"
        # key2 = "value2"
        # ...
        
        ## Threads config controls how many goroutines an agent cloud start to handle HTTP request.
        ## buffer is the size of jobs' buffering of worker channel.
        ## threads is the total number fo goroutines at running time.
        # [inputs.ddtrace.threads]
        # buffer = 100
        # threads = 8
        
        ## Storage config a local storage space in hard dirver to cache trace data.
        ## path is the local file path used to cache data.
        ## capacity is total space size(MB) used to store data.
        # [inputs.ddtrace.storage]
        # path = "./ddtrace_storage"
        # capacity = 5120
  - path: "/usr/local/datakit/conf.d/container/container.conf"
    name: container.conf
    value: |
      [[inputs.container]]
        docker_endpoint = "unix:///var/run/docker.sock"
        containerd_address = "/var/run/containerd/containerd.sock"

        enable_container_metric = true
        enable_k8s_metric = true
        enable_pod_metric = true

        ## Containers logs to include and exclude, default collect all containers. Globs accepted.
        container_include_log = []
        container_exclude_log = ["image:pubrepo.jiagouyun.com/datakit/logfwd*", "image:pubrepo.jiagouyun.com/datakit/datakit*"]

        exclude_pause_container = true

        ## Removes ANSI escape codes from text strings
        logging_remove_ansi_escape_codes = false

        kubernetes_url = "https://kubernetes.default:443"

        ## Authorization level:
        ##   bearer_token -> bearer_token_string -> TLS
        ## Use bearer token for authorization. ('bearer_token' takes priority)
        ## linux at:   /run/secrets/kubernetes.io/serviceaccount/token
        ## windows at: C:\var\run\secrets\kubernetes.io\serviceaccount\token
        bearer_token = "/run/secrets/kubernetes.io/serviceaccount/token"
        # bearer_token_string = "<your-token-string>"
      
        [inputs.container.tags]
          # some_tag = "some_value"
          # more_tag = "some_other_value"
  - path: "/usr/local/datakit/conf.d/log/logging.conf"
    name: logging.conf
    value: |
      [[inputs.logging]]
        # 日志文件列表，可以指定绝对路径，支持使用 glob 规则进行批量指定
        # 推荐使用绝对路径
        logfiles = [
        "/var/log/*",                          # 文件路径下所有文件
        "/var/log/sys*",                       # 文件路径下所有以 sys 前缀的文件
        "/var/log/syslog",                     # Unix 格式文件路径
        "C:/path/space 空格中文路径/some.txt", # Windows 风格文件路径
        "/var/log/*",                          # 文件路径下所有文件
        "/var/log/sys*",                       # 文件路径下所有以 sys 前缀的文件
        "/var/log/awsdemo/*"                     #demo 日志路径
        ]
  
        ## socket 目前支持两种协议：tcp/udp。建议开启内网端口防止安全隐患
        ## socket 和 log 目前只能选择其中之一，不能既通过文件采集，又通过 socket 采集
        socket = [
        "tcp://0.0.0.0:9540"
        "udp://0.0.0.0:9541"
        ]
  
        # 文件路径过滤，使用 glob 规则，符合任意一条过滤条件将不会对该文件进行采集
        ignore = [""]
      
        # 数据来源，如果为空，则默认使用 'default'
        source = ""
      
        # 新增标记 tag，如果为空，则默认使用 $source
        service = ""
      
        # pipeline 脚本路径，如果为空将使用 $source.p，如果 $source.p 不存在将不使用 pipeline
        pipeline = ""
      
        # 过滤对应 status
        #   `emerg`,`alert`,`critical`,`error`,`warning`,`info`,`debug`,`OK`
        ignore_status = []
      
        # 选择编码，如果编码有误会导致数据无法查看。默认为空即可
        #    `utf-8`, `utf-16le`, `utf-16le`, `gbk`, `gb18030` or ""
        character_encoding = ""
      
        ## 设置正则表达式，例如 ^\d{4}-\d{2}-\d{2} 行首匹配 YYYY-MM-DD 时间格式
        ## 符合此正则匹配的数据，将被认定为有效数据，否则会累积追加到上一条有效数据的末尾
        ## 使用 3 个单引号 '''this-regexp''' 避免转义
        ## 正则表达式链接：https://golang.org/pkg/regexp/syntax/#hdr-Syntax
        # multiline_match = '''^\S'''
      
        ## 是否开启自动多行模式，开启后会在 patterns 列表中匹配适用的多行规则
        auto_multiline_detection = true
        ## 配置自动多行的 patterns 列表，内容是多行规则的数组，即多个 multiline_match，如果为空则使用默认规则详见文档
        auto_multiline_extra_patterns = []
      
        ## 忽略不活跃的文件，例如文件最后一次修改是 20 分钟之前，距今超出 10m，则会忽略此文件
        ## 时间单位支持 "ms", "s", "m", "h"
        ignore_dead_log = "1h"
      
        ## 是否从文件首部开始读取
        from_beginning = false
  
        # 自定义 tags
        [inputs.logging.tags]
        # some_tag = "some_value"
        # more_tag = "some_other_value"
        # ...

extraEnvs:
- name: ENV_NAMESPACE
  value: guance-workshop
- name: ENV_GLOBAL_ELECTION_TAGS
  value: cluster_name_k8s=guance-workshop
fullnameOverride: ""
git_repos:
  enable: false
  git_branch: master
  git_interval: 1m
  git_key_path: '-'
  git_key_pw: '-'
  git_url: '-'
  is_use_key: false
image:
  pullPolicy: Always
  repository: pubrepo.guance.com/datakit/datakit
  tag: ""
iploc:
  enable: false
  image:
    repository: pubrepo.jiagouyun.com/datakit/iploc
    tag: "1.0"
kubeStateMetricsEnabled: true
nameOverride: ""
podAnnotations:
  datakit/logs: |
    [{"disable": true}]
resources:
  limits:
    cpu: 2000m
    memory: 4Gi
  requests:
    cpu: 200m
    memory: 128Mi
service:
  port: 9529
  type: ClusterIP
tolerations:
- operator: Exists
